{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-liabilities",
   "metadata": {},
   "source": [
    "# Calculating Average Travel Time to Other Destination Categories\n",
    "- Create a feature class for each destination type (healthcare, higher education, essential services) that contains the point locations, types, and capacity data.\n",
    "- For each TAZ, find out how many (and ideally which) destinations of each type are within a buffer of the TAZ centroid.\n",
    "- Flag each TAZ with whether it meets the threshold for the number of destinations within a buffer around the TAZ centroid for the type of destination.\n",
    "- Use model skims for travel times from TAZ centroid to TAZ centroid for all of the following modes: Drive (SOV as proxy), Transit, Rapid Transit, Bus, Walk.\n",
    "- Then pick the minimum time to reach a flagged TAZ and weight by TAZ population and use that for calculation of the average travel time for MPO.\n",
    "- Then flag origin TAZs as whether their minimum distance to a flagged TAZ is within the average threshold for MPO.\n",
    "\n",
    "\n",
    "Environment: base_py_37_omx_geop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import openmatrix as omx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "respiratory-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import all the CSVs that contain skims \n",
    "Walk_skim= omx.open_file('M:/LRTP/LRTP_AvgTT/out/Walk_skim.omx','r')\n",
    "#Import AM\n",
    "DAT_Boat_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_Boat_tr_skim.omx','r')\n",
    "DAT_CommRail_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_CommRail_tr_skim.omx','r')\n",
    "DAT_LocalBus_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_LocalBus_tr_skim.omx','r')\n",
    "DAT_RapidTransit_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_RapidTransit_tr_skim2.omx','r')\n",
    "WAT_Transit_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/WAT_for_All_tr_skim.omx','r')\n",
    "SOV_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/SOV_skim.omx','r')\n",
    "\n",
    "#put AM CSVs into Dictionary\n",
    "skims_AM = {'DAT_Boat':DAT_Boat_skim_AM, 'DAT_CR':DAT_CommRail_skim_AM, \n",
    "            'DAT_LB':DAT_LocalBus_skim_AM, 'DAT_RT':DAT_RapidTransit_skim_AM, \n",
    "            'WAT_TR':WAT_Transit_skim_AM, 'SOV':SOV_skim_AM, 'Walk': Walk_skim}\n",
    "\n",
    "#Import MD\n",
    "DAT_Boat_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_Boat_tr_skim.omx','r')\n",
    "DAT_CommRail_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_CommRail_tr_skim.omx','r')\n",
    "DAT_LocalBus_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_LocalBus_tr_skim.omx','r')\n",
    "DAT_RapidTransit_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_Rapid_Transit_tr_skim.omx','r')\n",
    "WAT_Transit_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\WAT_for_All_tr_skim.omx','r')\n",
    "SOV_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\SOV_skim.omx','r')\n",
    "\n",
    "#put MD CSVs into Dictionary\n",
    "skims_MD = {'DAT_Boat':DAT_Boat_skim_MD, 'DAT_CR':DAT_CommRail_skim_MD, \n",
    "            'DAT_LB':DAT_LocalBus_skim_MD, 'DAT_RT':DAT_RapidTransit_skim_MD, \n",
    "            'WAT_TR':WAT_Transit_skim_MD, 'SOV':SOV_skim_MD, 'Walk': Walk_skim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "corresponding-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import TAZ tables for Essential Services, Healthcare, and Higher Ed. \n",
    "dest_TAZs = pd.read_csv(r'M:/LRTP/LRTP_AvgTT/MPO_TAZ_ES_1m2.csv',header=0, sep=',',\n",
    "                        usecols=['taz', 'ES_FLAG_ALL','HIED_Count5', 'HLTH_COUNT1m'])\n",
    "#create table with column for each destination type that flags (0,1) which TAZs pass the destination threshold\n",
    "dest_TAZs['HIED_FLAG']=[1 if x >=1 else 0 for x in dest_TAZs['HIED_Count5']]\n",
    "dest_TAZs['HLTH_FLAG']=[1 if x >=1 else 0 for x in dest_TAZs['HLTH_COUNT1m']]\n",
    "\n",
    "#bring in population data for later\n",
    "tot_pop = pd.read_csv(r'M:/LRTP/LRTP_AvgTT/TAZ_Pop_CTPS.csv', header=0, sep=',', usecols=['TAZ_ID', 'Tot_Pop'])\n",
    "dest_TAZs = dest_TAZs.merge(tot_pop, how='left', left_on='taz', right_on ='TAZ_ID')\n",
    "\n",
    "#dest_TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "amber-mount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1594"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of total TAZs (this is for row and column names for matrices)\n",
    "tazs = dest_TAZs['taz'].tolist()\n",
    "tazs.sort()\n",
    "#make lists of only destination TAZs (this is for averaging)\n",
    "ES_list = dest_TAZs[dest_TAZs['ES_FLAG_ALL']==1]['taz'].tolist()\n",
    "HLTH_list = dest_TAZs[dest_TAZs['HLTH_FLAG']==1]['taz'].tolist()\n",
    "HIED_list = dest_TAZs[dest_TAZs['HIED_FLAG']==1]['taz'].tolist()\n",
    "len(HIED_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "desperate-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trips matrices\n",
    "AM_trips = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/AfterSC_Final_AM_Tables.omx','r')\n",
    "MD_trips = omx.open_file('M:/LRTP/LRTP_AvgTT/out/MD/AfterSC_Final_MD_Tables.omx','r')\n",
    "#turn into dataframes\n",
    "#AM_trips_DAT = pd.DataFrame((np.array(AM_trips['DAT_Boat'])+np.array(AM_trips['DAT_CR'])+\n",
    "                             #np.array(AM_trips['DAT_LB']) +np.array(AM_trips['DAT_RT']))[1:1902, 1:1902],\n",
    "                                   #index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "AM_trips_WAT = pd.DataFrame(np.array(AM_trips['WAT']))\n",
    "                            \n",
    "#MD_trips_DAT = pd.DataFrame((np.array(MD_trips['DAT_Boat'])+np.array(MD_trips['DAT_CR'])+\n",
    "                             #np.array(MD_trips['DAT_LB']) +np.array(MD_trips['DAT_RT']))[1:1902, 1:1902],\n",
    "                                   #index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "MD_trips_WAT = pd.DataFrame(np.array(MD_trips['WAT']))   \n",
    "\n",
    "#close omx\n",
    "AM_trips.close()\n",
    "MD_trips.close()\n",
    "\n",
    "#make trip total tables for transit so can do weighted average\n",
    "#AM_trips_AT = AM_trips_DAT + AM_trips_WAT\n",
    "#MD_trips_AT = MD_trips_DAT + MD_trips_WAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "former-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in add\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in add\n"
     ]
    }
   ],
   "source": [
    "##Sum the Skims to get Travel Time per Mode by Time of Day (loop through both AM and MD dictionaries)\n",
    "AM_Tables = {}\n",
    "MD_Tables = {}\n",
    "\n",
    "for x in skims_AM.keys():\n",
    "    #if x != 'SOV' and x != 'Walk' and x != 'WAT_TR':\n",
    "        #AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['Access Drive Time'])+np.array(skims_AM[x]['Access Walk Time'])\n",
    "                        #+np.array(skims_AM[x]['Dwelling Time'])+np.array(skims_AM[x]['Egress Drive Time'])\n",
    "                        #+np.array(skims_AM[x]['Egress Walk Time'])+np.array(skims_AM[x]['In-Vehicle Time'])\n",
    "                        #+np.array(skims_AM[x]['Initial Wait Time'])\n",
    "                        #+np.array(skims_AM[x]['Transfer Wait Time'])+np.array(skims_AM[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   #index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'WAT_TR':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['Access Walk Time'])\n",
    "                        +np.array(skims_AM[x]['Dwelling Time'])\n",
    "                        +np.array(skims_AM[x]['Egress Walk Time'])+np.array(skims_AM[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_AM[x]['Initial Wait Time'])\n",
    "                        +np.array(skims_AM[x]['Transfer Wait Time'])+np.array(skims_AM[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        \n",
    "        #Calculate Walk here so can use to replace null values in WAT_TR\n",
    "        AM_Tables['Walk'] = pd.DataFrame((np.array(skims_AM['Walk']['WalkTime']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        AM_Tables['Walk'][AM_Tables['Walk'] > 60] = None\n",
    "        \n",
    "        #replace TAZ to TAZ with walk for WAT\n",
    "        AM_Tables[x] = AM_Tables[x].combine_first(AM_Tables['Walk'])\n",
    "        \n",
    "    if x == 'SOV':\n",
    "        AM_Tables[x] = pd.DataFrame(np.array(skims_AM[x]['CongTime_wTerminalTimes'])[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    #if x == 'Walk':\n",
    "        #AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['WalkTime']))[1:1902, 1:1902],\n",
    "                                   #index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        #AM_Tables[x][AM_Tables[x] > 60] = None\n",
    "        \n",
    "for x in skims_MD.keys():\n",
    "    #if x != 'SOV' and x != 'Walk' and x != 'WAT_TR':\n",
    "        #MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['Access Drive Time'])+np.array(skims_MD[x]['Access Walk Time'])\n",
    "                        #+np.array(skims_MD[x]['Dwelling Time'])+np.array(skims_MD[x]['Egress Drive Time'])\n",
    "                        #+np.array(skims_MD[x]['Egress Walk Time'])+np.array(skims_MD[x]['In-Vehicle Time'])\n",
    "                        #+np.array(skims_MD[x]['Initial Wait Time'])\n",
    "                        #+np.array(skims_MD[x]['Transfer Wait Time'])+np.array(skims_MD[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   #index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'WAT_TR':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['Access Walk Time'])\n",
    "                        +np.array(skims_MD[x]['Dwelling Time'])\n",
    "                        +np.array(skims_MD[x]['Egress Walk Time'])+np.array(skims_MD[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_MD[x]['Initial Wait Time'])\n",
    "                        +np.array(skims_MD[x]['Transfer Wait Time'])+np.array(skims_MD[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        #Calculate walk so that can replace for WAT_TR where TAZ to same TAZ\n",
    "        MD_Tables['Walk'] = pd.DataFrame((np.array(skims_MD['Walk']['WalkTime']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        MD_Tables['Walk'][MD_Tables['Walk'] > 60] = None\n",
    "        #replace TAZ to TAZ with walk for WAT\n",
    "        MD_Tables[x] = MD_Tables[x].combine_first(MD_Tables['Walk'])\n",
    "    if x == 'SOV':\n",
    "        MD_Tables[x] = pd.DataFrame(np.array(skims_MD[x]['CongTime_wTerminalTimes'])[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    #if x == 'Walk':\n",
    "        #MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['WalkTime']))[1:1902, 1:1902],\n",
    "                                   #index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        #MD_Tables[x][MD_Tables[x] > 60] = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "documented-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close everything! \n",
    "Walk_skim.close()\n",
    "\n",
    "#DAT_Boat_skim_AM.close()\n",
    "#DAT_CommRail_skim_AM.close()\n",
    "#DAT_LocalBus_skim_AM.close()\n",
    "#DAT_RapidTransit_skim_AM.close()\n",
    "WAT_Transit_skim_AM.close()\n",
    "SOV_skim_AM.close()\n",
    "\n",
    "#DAT_Boat_skim_MD.close()\n",
    "#DAT_CommRail_skim_MD.close()\n",
    "#DAT_LocalBus_skim_MD.close()\n",
    "#DAT_RapidTransit_skim_MD.close()\n",
    "WAT_Transit_skim_MD.close()\n",
    "SOV_skim_MD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "concerned-telescope",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AM_TR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9eb93164584d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mMin_Dest_TAZ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mTravelTime\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mAM_Tables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AM_TR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mES_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#for every row get lowest 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mMin_Dest_TAZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#index (e.g. TAZ destinations)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mTravelTime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;31m# values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AM_TR'"
     ]
    }
   ],
   "source": [
    "#np.where(AM_Tables['AM_TR'].loc[:,ES_list].apply(lambda x: x.isin(x.nsmallest(3)), axis=1).loc[1] == True) \n",
    "#AM_Tables['AM_TR'].loc[:,ES_list].apply(lambda x: x.isin(x.nsmallest(3)), axis=1)\n",
    "\n",
    "'''Min_Dest_TAZ={}\n",
    "TravelTime ={}\n",
    "for index, row in AM_Tables['AM_TR'].loc[:,ES_list].iterrows():\n",
    "    Min_Dest_TAZ[index] = list(row.sort_values()[:3].index)#index (e.g. TAZ destinations)\n",
    "    TravelTime[index]=np.nansum(row.sort_values()[:3].values)/3 # values'''\n",
    "\n",
    "Min_Dest_TAZ={}\n",
    "TravelTime ={}\n",
    "for index, row in AM_Tables['AM_TR'].loc[:,ES_list].iterrows(): #for every row get lowest 3\n",
    "    Min_Dest_TAZ[index] = list(row.sort_values()[:3].index)#index (e.g. TAZ destinations)\n",
    "    TravelTime[index]=np.nansum(row.sort_values()[:3].values)/3 # values\n",
    "#turn into dataframe and join to main table\n",
    "temp = pd.DataFrame({'Min_Dest_TAZ': Min_Dest_TAZ}, {'TravelTime':TravelTime})\n",
    "#Avgs['ES_'+x] = Avgs['ES_'+x].merge(right = temp, how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "alleged-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Dest_TAZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TravelTime</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Min_Dest_TAZ\n",
       "TravelTime           NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "suffering-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make DAT tables (get min for each cell!)\n",
    "#AM_Tables['AM_DAT'] = np.fmin(np.fmin(AM_Tables['DAT_Boat'],AM_Tables['DAT_CR']), np.fmin(AM_Tables['DAT_LB'],AM_Tables['DAT_RT']))\n",
    "#MD_Tables['MD_DAT'] = np.fmin(np.fmin(MD_Tables['DAT_Boat'],MD_Tables['DAT_CR']), np.fmin(MD_Tables['DAT_LB'],MD_Tables['DAT_RT']))\n",
    "\n",
    "#Create new table in dictionary: All Transit\n",
    "    #take the average - weight it by # of trips for each type of transit\n",
    "#AM_Tables['AM_Transit'] = ((AM_Tables['AM_DAT']*AM_trips_DAT)+(AM_Tables['AM_WAT']*AM_trips_WAT))/(AM_trips_AT)\n",
    "#MD_Tables['MD_Transit'] = ((MD_Tables['MD_DAT']*MD_trips_DAT)+(MD_Tables['MD_WAT']*MD_trips_WAT))/(MD_trips_AT)\n",
    "    #take the lowest\n",
    "#AM_Tables['AM_TR'] = np.fmin(AM_Tables['AM_DAT'], AM_Tables['WAT_TR'])\n",
    "#MD_Tables['MD_TR'] = np.fmin(MD_Tables['MD_DAT'], MD_Tables['WAT_TR'])\n",
    "#use these if no drive access transit\n",
    "AM_Tables['AM_TR'] = AM_Tables['WAT_TR']\n",
    "MD_Tables['MD_TR'] = MD_Tables['WAT_TR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "friendly-lender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin taz</th>\n",
       "      <th>Min_Dest_TAZ</th>\n",
       "      <th>TravelTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 202, 36]</td>\n",
       "      <td>8.922270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2, 202, 35]</td>\n",
       "      <td>7.783895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[3, 36, 4]</td>\n",
       "      <td>7.627576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 3, 202]</td>\n",
       "      <td>9.946056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[5, 3, 41]</td>\n",
       "      <td>7.642837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2641</td>\n",
       "      <td>[2641, 2642, 754]</td>\n",
       "      <td>16.048322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2642</td>\n",
       "      <td>[2642, 2641, 2644]</td>\n",
       "      <td>27.435572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>2643</td>\n",
       "      <td>[2642, 2644, 754]</td>\n",
       "      <td>14.371516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>2644</td>\n",
       "      <td>[2644, 2642, 754]</td>\n",
       "      <td>16.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>2645</td>\n",
       "      <td>[2645, 2384, 2387]</td>\n",
       "      <td>23.914286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin taz        Min_Dest_TAZ  TravelTime\n",
       "0              1        [1, 202, 36]    8.922270\n",
       "1              2        [2, 202, 35]    7.783895\n",
       "2              3          [3, 36, 4]    7.627576\n",
       "3              4         [4, 3, 202]    9.946056\n",
       "4              5          [5, 3, 41]    7.642837\n",
       "...          ...                 ...         ...\n",
       "1896        2641   [2641, 2642, 754]   16.048322\n",
       "1897        2642  [2642, 2641, 2644]   27.435572\n",
       "1898        2643   [2642, 2644, 754]   14.371516\n",
       "1899        2644   [2644, 2642, 754]   16.839678\n",
       "1900        2645  [2645, 2384, 2387]   23.914286\n",
       "\n",
       "[1901 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculate Averages\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "\n",
    "    #want to end up with a table for each mode for each dest type with these columns: Origin TAZ, Dest TAZ, Time, Tot_Pop\n",
    "    #need to do AM for Healthcare and Essential Services, do MD for HiEd. (three tables per mode)\n",
    "Avgs = {}\n",
    "#Transit - ES\n",
    "#SOV - ES\n",
    "#Walking - ES\n",
    "for x in ['AM_TR', 'SOV', 'Walk']:\n",
    "    Avgs['ES_'+x] = AM_Tables[x].loc[:,ES_list] #restrict columns to just what is an ES destination TAZ\n",
    "    #do lowest 3 for transit\n",
    "    if x == 'AM_TR':\n",
    "        #get the 3 dest TAZs that are the closest\n",
    "        Min_Dest_TAZ={}\n",
    "        TravelTime ={}\n",
    "        for index, row in AM_Tables['AM_TR'].loc[:,ES_list].iterrows(): #for every row get lowest 3\n",
    "            Min_Dest_TAZ[index] = str(list(row.sort_values()[:3].index))#index (e.g. TAZ destinations)\n",
    "            TravelTime[index]=np.nansum(row.sort_values()[:3].values)/3 # values\n",
    "        #turn into dataframe and join to main table\n",
    "        temp = pd.DataFrame.from_dict(Min_Dest_TAZ, orient='index', columns=['Min_Dest_TAZ']).join(\n",
    "            other = pd.DataFrame.from_dict(TravelTime, orient='index', columns=['TravelTime']))\n",
    "        Avgs['ES_'+x] = Avgs['ES_'+x].join(other = temp, how = 'left')\n",
    "    else:\n",
    "        Avgs['ES_'+x]['Min_Dest_TAZ'] = Avgs['ES_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "        Avgs['ES_'+x]['TravelTime'] = Avgs['ES_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "#Transit - Healthcare\n",
    "#Walking - Healthcare\n",
    "#SOV - Healthcare\n",
    "for x in ['AM_TR', 'SOV', 'Walk']:\n",
    "    Avgs['HLTH_'+x] = AM_Tables[x].loc[:,HLTH_list] #restrict columns to just what is an HLTH destination TAZ\n",
    "    Avgs['HLTH_'+x]['Min_Dest_TAZ'] = Avgs['HLTH_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['HLTH_'+x]['TravelTime'] = Avgs['HLTH_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "#SOV - HiEd(MD)\n",
    "#Transit - HiEd (MD)\n",
    "#Walking - HiEd\n",
    "for x in ['MD_TR', 'SOV', 'Walk']:\n",
    "    Avgs['HIED_'+x] = MD_Tables[x].loc[:,HIED_list] #restrict columns to just what is an HiED destination TAZ\n",
    "    Avgs['HIED_'+x]['Min_Dest_TAZ'] = Avgs['HIED_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['HIED_'+x]['TravelTime'] = Avgs['HIED_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "\n",
    "#if want to not restrict to just transit (e.g. if O and D are same TAZ)\n",
    "#ES_RT.loc[ES_RT['origin taz'].isin(ES_list), 'Min_Dest_TAZ'] = ES_RT['origin taz'] #if taz is already a dest taz, set D taz to O taz\n",
    "#ES_RT.loc[ES_RT['origin taz'] == ES_RT['Min_Dest_TAZ'], 'TravelTime'] = None #if the taz is a dest taz, set TT to null\n",
    "#note here: so there will never be a transit value if the dest taz is the same as the origin taz\n",
    "#will need to replace with Walk or SOV here - depends on DAT or WAT?\n",
    "Avgs['ES_AM_TR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "editorial-incidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ES_AM_TR_Avg': 23.055239813307843,\n",
       " 'ES_SOV_Avg': 5.628888017575303,\n",
       " 'ES_Walk_Avg': 8.66032791433802,\n",
       " 'HLTH_AM_TR_Avg': 26.14402159508965,\n",
       " 'HLTH_SOV_Avg': 6.4588366804420065,\n",
       " 'HLTH_Walk_Avg': 10.006462587020875,\n",
       " 'HIED_MD_TR_Avg': 25.4199342019939,\n",
       " 'HIED_SOV_Avg': 6.466366023051868,\n",
       " 'HIED_Walk_Avg': 7.946976722620972}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculate Averages PART 2\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "#actually calculate averages\n",
    "AvgNums = {}\n",
    "for x in Avgs.keys():\n",
    "    Avgs[x] = Avgs[x].merge(dest_TAZs, how = 'left', left_on = 'origin taz', right_on = 'taz') #merge to have all data in one table\n",
    "    Avgs[x]['TT_Pop'] = Avgs[x]['TravelTime']*Avgs[x]['Tot_Pop'] #calculate time * pop (weight)\n",
    "    avg = np.nansum(Avgs[x]['TT_Pop'])/np.nansum(Avgs[x]['Tot_Pop']) #make the actual avg, excluding nan values\n",
    "    AvgNums[x+'_Avg'] = avg #add avg to dictionary with id\n",
    "    Avgs[x]['Avg'] = avg #add a avg field for calc later\n",
    "AvgNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "injured-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make Flag Tables\n",
    "#if the TAZ has access to a destination TAZ within the MPO average for that mode, flag.\n",
    "    #How do I make this into a table?  - maybe copy the TAZ to TAZ table and clear its contents, then just go down the column of all the destination TAZs and query the skim table for that mode and TOD.\n",
    "    #where column name is in list (aka field in the table that flags destination TAZs for each type)\n",
    "for x in Avgs.keys():\n",
    "    Avgs[x]['AvgTT_Flag'] = np.where(Avgs[x]['TravelTime'] <= Avgs[x]['Avg'], 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "editorial-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin taz        2645.000000\n",
       "Min_Dest_TAZ      2642.000000\n",
       "TravelTime          51.282684\n",
       "taz               2645.000000\n",
       "ES_FLAG_ALL          1.000000\n",
       "HIED_Count5         49.000000\n",
       "HLTH_COUNT1m        23.000000\n",
       "HIED_FLAG            1.000000\n",
       "HLTH_FLAG            1.000000\n",
       "TAZ_ID            2645.000000\n",
       "Tot_Pop           5151.000000\n",
       "TT_Pop          184343.428539\n",
       "Avg                 10.006463\n",
       "AvgTT_Flag           1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avgs['HLTH_Walk'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fiscal-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in Avgs.keys():\n",
    "    Avgs[x].to_csv('M:\\LRTP\\LRTP_AvgTT\\Avgs_Walk\\Avg_'+x+'.csv',sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN (works - use for future)\n",
    "\n",
    "##Calculate Averages\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "\n",
    "    #want to end up with a table for each mode for each dest type with these columns: Origin TAZ, Dest TAZ, Time, Tot_Pop\n",
    "    #need to do AM for Healthcare and Essential Services, do MD for HiEd. (three tables per mode)\n",
    "ES_RT = AM_Tables['DAT_RT'].loc[:,ES_list] #restrict columns to just what is an ES destination TAZ\n",
    "ES_RT['Min_Dest_TAZ'] = ES_RT.idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "ES_RT['TravelTime'] = ES_RT.min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "ES_RT = ES_RT.reset_index() #turn index into origin taz field\n",
    "ES_RT = ES_RT.rename(columns = {'index':'origin taz'})\n",
    "\n",
    "ES_RT = ES_RT[['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "#if want to not restrict to just transit (e.g. if O and D are same TAZ)\n",
    "#ES_RT.loc[ES_RT['origin taz'].isin(ES_list), 'Min_Dest_TAZ'] = ES_RT['origin taz'] #if taz is already a dest taz, set D taz to O taz\n",
    "#ES_RT.loc[ES_RT['origin taz'] == ES_RT['Min_Dest_TAZ'], 'TravelTime'] = None #if the taz is a dest taz, set TT to null\n",
    "#note here: so there will never be a transit value if the dest taz is the same as the origin taz\n",
    "#will need to replace with Walk or SOV here - depends on DAT or WAT?\n",
    "ES_RT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base_py_37_omx_geop]",
   "language": "python",
   "name": "conda-env-base_py_37_omx_geop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
