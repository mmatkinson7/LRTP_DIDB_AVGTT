{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-liabilities",
   "metadata": {},
   "source": [
    "# Calculating Average Travel Time to Other Destination Categories\n",
    "- Create a feature class for each destination type (healthcare, higher education, essential services) that contains the point locations, types, and capacity data.\n",
    "- For each TAZ, find out how many (and ideally which) destinations of each type are within a buffer of the TAZ centroid.\n",
    "- Flag each TAZ with whether it meets the threshold for the number of destinations within a buffer around the TAZ centroid for the type of destination.\n",
    "- Use model skims for travel times from TAZ centroid to TAZ centroid for all of the following modes: Drive (SOV as proxy), Transit, Rapid Transit, Bus, Walk.\n",
    "- Then pick the minimum time to reach a flagged TAZ and weight by TAZ population and use that for calculation of the average travel time for MPO.\n",
    "- Then flag origin TAZs as whether their minimum distance to a flagged TAZ is within the average threshold for MPO.\n",
    "\n",
    "\n",
    "Environment: base_py_37_omx_geop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import openmatrix as omx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "respiratory-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import all the CSVs that contain skims \n",
    "Walk_skim= omx.open_file('M:/LRTP/LRTP_AvgTT/out/Walk_skim.omx','r')\n",
    "#Import AM\n",
    "DAT_Boat_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_Boat_tr_skim.omx','r')\n",
    "DAT_CommRail_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_CommRail_tr_skim.omx','r')\n",
    "DAT_LocalBus_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_LocalBus_tr_skim.omx','r')\n",
    "DAT_RapidTransit_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_RapidTransit_tr_skim2.omx','r')\n",
    "WAT_Transit_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/WAT_for_All_tr_skim.omx','r')\n",
    "SOV_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/SOV_skim.omx','r')\n",
    "\n",
    "#put AM CSVs into Dictionary\n",
    "skims_AM = {'DAT_Boat':DAT_Boat_skim_AM, 'DAT_CR':DAT_CommRail_skim_AM, \n",
    "            'DAT_LB':DAT_LocalBus_skim_AM, 'DAT_RT':DAT_RapidTransit_skim_AM, \n",
    "            'WAT_TR':WAT_Transit_skim_AM, 'SOV':SOV_skim_AM, 'Walk': Walk_skim}\n",
    "\n",
    "#Import MD\n",
    "DAT_Boat_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_Boat_tr_skim.omx','r')\n",
    "DAT_CommRail_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_CommRail_tr_skim.omx','r')\n",
    "DAT_LocalBus_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_LocalBus_tr_skim.omx','r')\n",
    "DAT_RapidTransit_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_Rapid_Transit_tr_skim.omx','r')\n",
    "WAT_Transit_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\WAT_for_All_tr_skim.omx','r')\n",
    "SOV_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\SOV_skim.omx','r')\n",
    "\n",
    "#put MD CSVs into Dictionary\n",
    "skims_MD = {'DAT_Boat':DAT_Boat_skim_MD, 'DAT_CR':DAT_CommRail_skim_MD, \n",
    "            'DAT_LB':DAT_LocalBus_skim_MD, 'DAT_RT':DAT_RapidTransit_skim_MD, \n",
    "            'WAT_TR':WAT_Transit_skim_MD, 'SOV':SOV_skim_MD, 'Walk': Walk_skim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "corresponding-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import TAZ tables for Essential Services, Healthcare, and Higher Ed. \n",
    "dest_TAZs = pd.read_csv(r'M:/LRTP/LRTP_AvgTT/MPO_TAZ_ES_1m2.csv',header=0, sep=',',\n",
    "                        usecols=['taz', 'ES_FLAG_ALL','HIED_Count5', 'HLTH_COUNT1m'])\n",
    "#create table with column for each destination type that flags (0,1) which TAZs pass the destination threshold\n",
    "dest_TAZs['HIED_FLAG']=[1 if x >=1 else 0 for x in dest_TAZs['HIED_Count5']]\n",
    "dest_TAZs['HLTH_FLAG']=[1 if x >=1 else 0 for x in dest_TAZs['HLTH_COUNT1m']]\n",
    "\n",
    "#bring in population data for later\n",
    "tot_pop = pd.read_csv(r'M:/LRTP/LRTP_AvgTT/TAZ_Pop_CTPS.csv', header=0, sep=',', usecols=['TAZ_ID', 'Tot_Pop'])\n",
    "dest_TAZs = dest_TAZs.merge(tot_pop, how='left', left_on='taz', right_on ='TAZ_ID')\n",
    "\n",
    "#dest_TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "amber-mount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1594"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of total TAZs (this is for row and column names for matrices)\n",
    "tazs = dest_TAZs['taz'].tolist()\n",
    "tazs.sort()\n",
    "#make lists of only destination TAZs (this is for averaging)\n",
    "ES_list = dest_TAZs[dest_TAZs['ES_FLAG_ALL']==1]['taz'].tolist()\n",
    "HLTH_list = dest_TAZs[dest_TAZs['HLTH_FLAG']==1]['taz'].tolist()\n",
    "HIED_list = dest_TAZs[dest_TAZs['HIED_FLAG']==1]['taz'].tolist()\n",
    "len(HIED_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "desperate-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trips matrices\n",
    "AM_trips = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/AfterSC_Final_AM_Tables.omx','r')\n",
    "MD_trips = omx.open_file('M:/LRTP/LRTP_AvgTT/out/MD/AfterSC_Final_MD_Tables.omx','r')\n",
    "#turn into dataframes\n",
    "AM_trips_DAT = pd.DataFrame((np.array(AM_trips['DAT_Boat'])+np.array(AM_trips['DAT_CR'])+\n",
    "                             np.array(AM_trips['DAT_LB']) +np.array(AM_trips['DAT_RT']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "AM_trips_WAT = pd.DataFrame(np.array(AM_trips['WAT']))\n",
    "                            \n",
    "MD_trips_DAT = pd.DataFrame((np.array(MD_trips['DAT_Boat'])+np.array(MD_trips['DAT_CR'])+\n",
    "                             np.array(MD_trips['DAT_LB']) +np.array(MD_trips['DAT_RT']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "MD_trips_WAT = pd.DataFrame(np.array(MD_trips['WAT']))   \n",
    "\n",
    "#close omx\n",
    "AM_trips.close()\n",
    "MD_trips.close()\n",
    "\n",
    "#make trip total tables for transit so can do weighted average\n",
    "AM_trips_AT = AM_trips_DAT + AM_trips_WAT\n",
    "MD_trips_AT = MD_trips_DAT + MD_trips_WAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "former-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in add\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in add\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: overflow encountered in add\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: overflow encountered in add\n"
     ]
    }
   ],
   "source": [
    "##Sum the Skims to get Travel Time per Mode by Time of Day (loop through both AM and MD dictionaries)\n",
    "AM_Tables = {}\n",
    "MD_Tables = {}\n",
    "\n",
    "for x in skims_AM.keys():\n",
    "    if x != 'SOV' and x != 'Walk' and x != 'WAT_TR':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['Access Drive Time'])+np.array(skims_AM[x]['Access Walk Time'])\n",
    "                        +np.array(skims_AM[x]['Dwelling Time'])+np.array(skims_AM[x]['Egress Drive Time'])\n",
    "                        +np.array(skims_AM[x]['Egress Walk Time'])+np.array(skims_AM[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_AM[x]['Initial Wait Time'])+np.array(skims_AM[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_AM[x]['Transfer Wait Time'])+np.array(skims_AM[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'WAT_TR':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['Access Walk Time'])\n",
    "                        +np.array(skims_AM[x]['Dwelling Time'])\n",
    "                        +np.array(skims_AM[x]['Egress Walk Time'])+np.array(skims_AM[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_AM[x]['Initial Wait Time'])+np.array(skims_AM[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_AM[x]['Transfer Wait Time'])+np.array(skims_AM[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'SOV':\n",
    "        AM_Tables[x] = pd.DataFrame(np.array(skims_AM[x]['CongTime_wTerminalTimes'])[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'Walk':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['WalkTime']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        AM_Tables[x][AM_Tables[x] > 60] = None\n",
    "        \n",
    "for x in skims_MD.keys():\n",
    "    if x != 'SOV' and x != 'Walk' and x != 'WAT_TR':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['Access Drive Time'])+np.array(skims_MD[x]['Access Walk Time'])\n",
    "                        +np.array(skims_MD[x]['Dwelling Time'])+np.array(skims_MD[x]['Egress Drive Time'])\n",
    "                        +np.array(skims_MD[x]['Egress Walk Time'])+np.array(skims_MD[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_MD[x]['Initial Wait Time'])+np.array(skims_MD[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_MD[x]['Transfer Wait Time'])+np.array(skims_MD[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'WAT_TR':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['Access Walk Time'])\n",
    "                        +np.array(skims_MD[x]['Dwelling Time'])\n",
    "                        +np.array(skims_MD[x]['Egress Walk Time'])+np.array(skims_MD[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_MD[x]['Initial Wait Time'])+np.array(skims_MD[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_MD[x]['Transfer Wait Time'])+np.array(skims_MD[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'SOV':\n",
    "        MD_Tables[x] = pd.DataFrame(np.array(skims_MD[x]['CongTime_wTerminalTimes'])[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'Walk':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['WalkTime']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        MD_Tables[x][MD_Tables[x] > 60] = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "documented-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close everything! \n",
    "Walk_skim.close()\n",
    "\n",
    "DAT_Boat_skim_AM.close()\n",
    "DAT_CommRail_skim_AM.close()\n",
    "DAT_LocalBus_skim_AM.close()\n",
    "DAT_RapidTransit_skim_AM.close()\n",
    "WAT_Transit_skim_AM.close()\n",
    "SOV_skim_AM.close()\n",
    "\n",
    "DAT_Boat_skim_MD.close()\n",
    "DAT_CommRail_skim_MD.close()\n",
    "DAT_LocalBus_skim_MD.close()\n",
    "DAT_RapidTransit_skim_MD.close()\n",
    "WAT_Transit_skim_MD.close()\n",
    "SOV_skim_MD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "concerned-telescope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2636</th>\n",
       "      <th>2637</th>\n",
       "      <th>2638</th>\n",
       "      <th>2639</th>\n",
       "      <th>2640</th>\n",
       "      <th>2641</th>\n",
       "      <th>2642</th>\n",
       "      <th>2643</th>\n",
       "      <th>2644</th>\n",
       "      <th>2645</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.956330</td>\n",
       "      <td>13.643062</td>\n",
       "      <td>13.173339</td>\n",
       "      <td>14.308445</td>\n",
       "      <td>14.404925</td>\n",
       "      <td>14.994924</td>\n",
       "      <td>15.425624</td>\n",
       "      <td>15.913063</td>\n",
       "      <td>15.545771</td>\n",
       "      <td>16.791195</td>\n",
       "      <td>...</td>\n",
       "      <td>55.134129</td>\n",
       "      <td>56.081024</td>\n",
       "      <td>59.575680</td>\n",
       "      <td>61.106041</td>\n",
       "      <td>61.432808</td>\n",
       "      <td>58.969299</td>\n",
       "      <td>56.629562</td>\n",
       "      <td>56.550686</td>\n",
       "      <td>56.036140</td>\n",
       "      <td>53.349316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.328058</td>\n",
       "      <td>13.031709</td>\n",
       "      <td>12.954587</td>\n",
       "      <td>14.101412</td>\n",
       "      <td>13.360558</td>\n",
       "      <td>14.787889</td>\n",
       "      <td>14.381256</td>\n",
       "      <td>14.868696</td>\n",
       "      <td>14.501403</td>\n",
       "      <td>15.746826</td>\n",
       "      <td>...</td>\n",
       "      <td>54.089760</td>\n",
       "      <td>55.036659</td>\n",
       "      <td>58.531311</td>\n",
       "      <td>60.061672</td>\n",
       "      <td>60.388439</td>\n",
       "      <td>57.924931</td>\n",
       "      <td>55.585194</td>\n",
       "      <td>55.506317</td>\n",
       "      <td>54.991772</td>\n",
       "      <td>52.304951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.579362</td>\n",
       "      <td>14.713282</td>\n",
       "      <td>11.080709</td>\n",
       "      <td>12.191051</td>\n",
       "      <td>11.636251</td>\n",
       "      <td>12.877529</td>\n",
       "      <td>12.656950</td>\n",
       "      <td>13.144391</td>\n",
       "      <td>12.777098</td>\n",
       "      <td>14.210814</td>\n",
       "      <td>...</td>\n",
       "      <td>53.082787</td>\n",
       "      <td>54.029686</td>\n",
       "      <td>57.524338</td>\n",
       "      <td>59.054699</td>\n",
       "      <td>59.381466</td>\n",
       "      <td>56.917957</td>\n",
       "      <td>54.578220</td>\n",
       "      <td>54.499344</td>\n",
       "      <td>53.984798</td>\n",
       "      <td>51.297977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.783459</td>\n",
       "      <td>16.917377</td>\n",
       "      <td>12.629704</td>\n",
       "      <td>11.151484</td>\n",
       "      <td>11.763741</td>\n",
       "      <td>12.278058</td>\n",
       "      <td>12.515465</td>\n",
       "      <td>13.002905</td>\n",
       "      <td>12.635612</td>\n",
       "      <td>14.069328</td>\n",
       "      <td>...</td>\n",
       "      <td>54.838863</td>\n",
       "      <td>55.785759</td>\n",
       "      <td>59.280415</td>\n",
       "      <td>60.810776</td>\n",
       "      <td>61.137543</td>\n",
       "      <td>58.674034</td>\n",
       "      <td>56.334297</td>\n",
       "      <td>56.255421</td>\n",
       "      <td>55.740875</td>\n",
       "      <td>53.054050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.900571</td>\n",
       "      <td>16.034492</td>\n",
       "      <td>11.746818</td>\n",
       "      <td>12.616402</td>\n",
       "      <td>10.915481</td>\n",
       "      <td>13.129595</td>\n",
       "      <td>11.812959</td>\n",
       "      <td>12.300400</td>\n",
       "      <td>11.933106</td>\n",
       "      <td>13.366822</td>\n",
       "      <td>...</td>\n",
       "      <td>53.955975</td>\n",
       "      <td>54.902870</td>\n",
       "      <td>58.397526</td>\n",
       "      <td>59.927887</td>\n",
       "      <td>60.254654</td>\n",
       "      <td>57.791145</td>\n",
       "      <td>55.451408</td>\n",
       "      <td>55.372532</td>\n",
       "      <td>54.857986</td>\n",
       "      <td>52.171162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>100.095909</td>\n",
       "      <td>99.735359</td>\n",
       "      <td>96.432137</td>\n",
       "      <td>97.009842</td>\n",
       "      <td>95.512566</td>\n",
       "      <td>94.778748</td>\n",
       "      <td>96.070679</td>\n",
       "      <td>95.046120</td>\n",
       "      <td>95.032318</td>\n",
       "      <td>93.998604</td>\n",
       "      <td>...</td>\n",
       "      <td>12.640846</td>\n",
       "      <td>9.015627</td>\n",
       "      <td>7.432114</td>\n",
       "      <td>9.653997</td>\n",
       "      <td>6.740612</td>\n",
       "      <td>4.141993</td>\n",
       "      <td>5.635468</td>\n",
       "      <td>8.525560</td>\n",
       "      <td>10.164310</td>\n",
       "      <td>17.124113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>97.106026</td>\n",
       "      <td>96.745476</td>\n",
       "      <td>93.442253</td>\n",
       "      <td>94.019958</td>\n",
       "      <td>92.522682</td>\n",
       "      <td>91.788864</td>\n",
       "      <td>93.080795</td>\n",
       "      <td>92.056236</td>\n",
       "      <td>92.042435</td>\n",
       "      <td>91.008720</td>\n",
       "      <td>...</td>\n",
       "      <td>11.385929</td>\n",
       "      <td>7.113874</td>\n",
       "      <td>6.484854</td>\n",
       "      <td>10.083163</td>\n",
       "      <td>7.850987</td>\n",
       "      <td>5.150562</td>\n",
       "      <td>3.643444</td>\n",
       "      <td>5.535677</td>\n",
       "      <td>7.174427</td>\n",
       "      <td>14.134228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>96.241356</td>\n",
       "      <td>95.880806</td>\n",
       "      <td>92.577583</td>\n",
       "      <td>93.155289</td>\n",
       "      <td>91.658012</td>\n",
       "      <td>90.924194</td>\n",
       "      <td>92.216125</td>\n",
       "      <td>91.191566</td>\n",
       "      <td>91.177765</td>\n",
       "      <td>90.144051</td>\n",
       "      <td>...</td>\n",
       "      <td>10.957171</td>\n",
       "      <td>6.613282</td>\n",
       "      <td>9.173223</td>\n",
       "      <td>12.771533</td>\n",
       "      <td>10.852390</td>\n",
       "      <td>8.388882</td>\n",
       "      <td>5.606019</td>\n",
       "      <td>5.421509</td>\n",
       "      <td>6.309753</td>\n",
       "      <td>13.269554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>94.726379</td>\n",
       "      <td>94.365829</td>\n",
       "      <td>91.062607</td>\n",
       "      <td>91.640312</td>\n",
       "      <td>90.143036</td>\n",
       "      <td>89.409218</td>\n",
       "      <td>90.701149</td>\n",
       "      <td>89.676590</td>\n",
       "      <td>89.662788</td>\n",
       "      <td>88.629074</td>\n",
       "      <td>...</td>\n",
       "      <td>8.761540</td>\n",
       "      <td>6.382905</td>\n",
       "      <td>9.973005</td>\n",
       "      <td>13.680373</td>\n",
       "      <td>11.817974</td>\n",
       "      <td>9.354466</td>\n",
       "      <td>7.014727</td>\n",
       "      <td>6.935852</td>\n",
       "      <td>5.506815</td>\n",
       "      <td>11.572702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>89.294762</td>\n",
       "      <td>88.934212</td>\n",
       "      <td>85.630989</td>\n",
       "      <td>86.208694</td>\n",
       "      <td>84.711418</td>\n",
       "      <td>83.977600</td>\n",
       "      <td>85.269531</td>\n",
       "      <td>84.244972</td>\n",
       "      <td>84.231171</td>\n",
       "      <td>83.197456</td>\n",
       "      <td>...</td>\n",
       "      <td>10.308640</td>\n",
       "      <td>11.539578</td>\n",
       "      <td>13.810531</td>\n",
       "      <td>16.280552</td>\n",
       "      <td>16.691553</td>\n",
       "      <td>15.476322</td>\n",
       "      <td>13.136582</td>\n",
       "      <td>13.057707</td>\n",
       "      <td>10.706314</td>\n",
       "      <td>5.783285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1          2          3          4          5          6     \\\n",
       "1      12.956330  13.643062  13.173339  14.308445  14.404925  14.994924   \n",
       "2      14.328058  13.031709  12.954587  14.101412  13.360558  14.787889   \n",
       "3      14.579362  14.713282  11.080709  12.191051  11.636251  12.877529   \n",
       "4      16.783459  16.917377  12.629704  11.151484  11.763741  12.278058   \n",
       "5      15.900571  16.034492  11.746818  12.616402  10.915481  13.129595   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2641  100.095909  99.735359  96.432137  97.009842  95.512566  94.778748   \n",
       "2642   97.106026  96.745476  93.442253  94.019958  92.522682  91.788864   \n",
       "2643   96.241356  95.880806  92.577583  93.155289  91.658012  90.924194   \n",
       "2644   94.726379  94.365829  91.062607  91.640312  90.143036  89.409218   \n",
       "2645   89.294762  88.934212  85.630989  86.208694  84.711418  83.977600   \n",
       "\n",
       "           7          8          9          10    ...       2636       2637  \\\n",
       "1     15.425624  15.913063  15.545771  16.791195  ...  55.134129  56.081024   \n",
       "2     14.381256  14.868696  14.501403  15.746826  ...  54.089760  55.036659   \n",
       "3     12.656950  13.144391  12.777098  14.210814  ...  53.082787  54.029686   \n",
       "4     12.515465  13.002905  12.635612  14.069328  ...  54.838863  55.785759   \n",
       "5     11.812959  12.300400  11.933106  13.366822  ...  53.955975  54.902870   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2641  96.070679  95.046120  95.032318  93.998604  ...  12.640846   9.015627   \n",
       "2642  93.080795  92.056236  92.042435  91.008720  ...  11.385929   7.113874   \n",
       "2643  92.216125  91.191566  91.177765  90.144051  ...  10.957171   6.613282   \n",
       "2644  90.701149  89.676590  89.662788  88.629074  ...   8.761540   6.382905   \n",
       "2645  85.269531  84.244972  84.231171  83.197456  ...  10.308640  11.539578   \n",
       "\n",
       "           2638       2639       2640       2641       2642       2643  \\\n",
       "1     59.575680  61.106041  61.432808  58.969299  56.629562  56.550686   \n",
       "2     58.531311  60.061672  60.388439  57.924931  55.585194  55.506317   \n",
       "3     57.524338  59.054699  59.381466  56.917957  54.578220  54.499344   \n",
       "4     59.280415  60.810776  61.137543  58.674034  56.334297  56.255421   \n",
       "5     58.397526  59.927887  60.254654  57.791145  55.451408  55.372532   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2641   7.432114   9.653997   6.740612   4.141993   5.635468   8.525560   \n",
       "2642   6.484854  10.083163   7.850987   5.150562   3.643444   5.535677   \n",
       "2643   9.173223  12.771533  10.852390   8.388882   5.606019   5.421509   \n",
       "2644   9.973005  13.680373  11.817974   9.354466   7.014727   6.935852   \n",
       "2645  13.810531  16.280552  16.691553  15.476322  13.136582  13.057707   \n",
       "\n",
       "           2644       2645  \n",
       "1     56.036140  53.349316  \n",
       "2     54.991772  52.304951  \n",
       "3     53.984798  51.297977  \n",
       "4     55.740875  53.054050  \n",
       "5     54.857986  52.171162  \n",
       "...         ...        ...  \n",
       "2641  10.164310  17.124113  \n",
       "2642   7.174427  14.134228  \n",
       "2643   6.309753  13.269554  \n",
       "2644   5.506815  11.572702  \n",
       "2645  10.706314   5.783285  \n",
       "\n",
       "[1901 rows x 1901 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AM_Tables['SOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "suffering-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make DAT tables (get min for each cell!)\n",
    "AM_Tables['AM_DAT'] = np.fmin(np.fmin(AM_Tables['DAT_Boat'],AM_Tables['DAT_CR']), np.fmin(AM_Tables['DAT_LB'],AM_Tables['DAT_RT']))\n",
    "MD_Tables['MD_DAT'] = np.fmin(np.fmin(MD_Tables['DAT_Boat'],MD_Tables['DAT_CR']), np.fmin(MD_Tables['DAT_LB'],MD_Tables['DAT_RT']))\n",
    "\n",
    "#Create new table in dictionary: All Transit\n",
    "    #take the average - weight it by # of trips for each type of transit\n",
    "#AM_Tables['AM_Transit'] = ((AM_Tables['AM_DAT']*AM_trips_DAT)+(AM_Tables['AM_WAT']*AM_trips_WAT))/(AM_trips_AT)\n",
    "#MD_Tables['MD_Transit'] = ((MD_Tables['MD_DAT']*MD_trips_DAT)+(MD_Tables['MD_WAT']*MD_trips_WAT))/(MD_trips_AT)\n",
    "    #take the lowest\n",
    "#AM_Tables['AM_TR'] = np.fmin(AM_Tables['AM_DAT'], AM_Tables['WAT_TR'])\n",
    "#MD_Tables['MD_TR'] = np.fmin(MD_Tables['MD_DAT'], MD_Tables['WAT_TR'])\n",
    "#use these if no drive access transit\n",
    "AM_Tables['AM_TR'] = AM_Tables['WAT_TR']\n",
    "MD_Tables['MD_TR'] = MD_Tables['WAT_TR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "friendly-lender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin taz</th>\n",
       "      <th>Min_Dest_TAZ</th>\n",
       "      <th>TravelTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>12.735808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>2643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>2644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>2645</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin taz  Min_Dest_TAZ  TravelTime\n",
       "0              1         202.0   12.735808\n",
       "1              2           3.0    3.000000\n",
       "2              3           4.0    4.000000\n",
       "3              4           3.0    3.000000\n",
       "4              5           3.0    3.000000\n",
       "...          ...           ...         ...\n",
       "1896        2641           NaN         NaN\n",
       "1897        2642           NaN         NaN\n",
       "1898        2643           NaN         NaN\n",
       "1899        2644           NaN         NaN\n",
       "1900        2645          15.0   15.000000\n",
       "\n",
       "[1901 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculate Averages\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "\n",
    "    #want to end up with a table for each mode for each dest type with these columns: Origin TAZ, Dest TAZ, Time, Tot_Pop\n",
    "    #need to do AM for Healthcare and Essential Services, do MD for HiEd. (three tables per mode)\n",
    "Avgs = {}\n",
    "#Transit - ES\n",
    "#SOV - ES\n",
    "#Walking - ES\n",
    "for x in ['AM_TR', 'SOV', 'Walk']:\n",
    "    Avgs['ES_'+x] = AM_Tables[x].loc[:,ES_list] #restrict columns to just what is an ES destination TAZ\n",
    "    Avgs['ES_'+x]['Min_Dest_TAZ'] = Avgs['ES_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['ES_'+x]['TravelTime'] = Avgs['ES_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "#Transit - Healthcare\n",
    "#Walking - Healthcare\n",
    "#SOV - Healthcare\n",
    "for x in ['AM_TR', 'SOV', 'Walk']:\n",
    "    Avgs['HLTH_'+x] = AM_Tables[x].loc[:,HLTH_list] #restrict columns to just what is an HLTH destination TAZ\n",
    "    Avgs['HLTH_'+x]['Min_Dest_TAZ'] = Avgs['HLTH_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['HLTH_'+x]['TravelTime'] = Avgs['HLTH_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "#SOV - HiEd(MD)\n",
    "#Transit - HiEd (MD)\n",
    "#Walking - HiEd\n",
    "for x in ['MD_TR', 'SOV', 'Walk']:\n",
    "    Avgs['HIED_'+x] = MD_Tables[x].loc[:,HIED_list] #restrict columns to just what is an HiED destination TAZ\n",
    "    Avgs['HIED_'+x]['Min_Dest_TAZ'] = Avgs['HIED_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['HIED_'+x]['TravelTime'] = Avgs['HIED_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "\n",
    "#if want to not restrict to just transit (e.g. if O and D are same TAZ)\n",
    "#ES_RT.loc[ES_RT['origin taz'].isin(ES_list), 'Min_Dest_TAZ'] = ES_RT['origin taz'] #if taz is already a dest taz, set D taz to O taz\n",
    "#ES_RT.loc[ES_RT['origin taz'] == ES_RT['Min_Dest_TAZ'], 'TravelTime'] = None #if the taz is a dest taz, set TT to null\n",
    "#note here: so there will never be a transit value if the dest taz is the same as the origin taz\n",
    "#will need to replace with Walk or SOV here - depends on DAT or WAT?\n",
    "Avgs['HIED_MD_TR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "editorial-incidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ES_AM_TR_Avg': 23.055239813307843,\n",
       " 'ES_SOV_Avg': 5.628888017575303,\n",
       " 'ES_Walk_Avg': 8.66032791433802,\n",
       " 'HLTH_AM_TR_Avg': 26.14402159508965,\n",
       " 'HLTH_SOV_Avg': 6.4588366804420065,\n",
       " 'HLTH_Walk_Avg': 10.006462587020875,\n",
       " 'HIED_MD_TR_Avg': 25.4199342019939,\n",
       " 'HIED_SOV_Avg': 6.466366023051868,\n",
       " 'HIED_Walk_Avg': 7.946976722620972}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculate Averages PART 2\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "#actually calculate averages\n",
    "AvgNums = {}\n",
    "for x in Avgs.keys():\n",
    "    Avgs[x] = Avgs[x].merge(dest_TAZs, how = 'left', left_on = 'origin taz', right_on = 'taz') #merge to have all data in one table\n",
    "    Avgs[x]['TT_Pop'] = Avgs[x]['TravelTime']*Avgs[x]['Tot_Pop'] #calculate time * pop (weight)\n",
    "    avg = np.nansum(Avgs[x]['TT_Pop'])/np.nansum(Avgs[x]['Tot_Pop']) #make the actual avg, excluding nan values\n",
    "    AvgNums[x+'_Avg'] = avg #add avg to dictionary with id\n",
    "    Avgs[x]['Avg'] = avg #add a avg field for calc later\n",
    "AvgNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "injured-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make Flag Tables\n",
    "#if the TAZ has access to a destination TAZ within the MPO average for that mode, flag.\n",
    "    #How do I make this into a table?  - maybe copy the TAZ to TAZ table and clear its contents, then just go down the column of all the destination TAZs and query the skim table for that mode and TOD.\n",
    "    #where column name is in list (aka field in the table that flags destination TAZs for each type)\n",
    "for x in Avgs.keys():\n",
    "    Avgs[x]['AvgTT_Flag'] = np.where(Avgs[x]['TravelTime'] <= Avgs[x]['Avg'], 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "editorial-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin taz        2645.000000\n",
       "Min_Dest_TAZ      2642.000000\n",
       "TravelTime          51.282684\n",
       "taz               2645.000000\n",
       "ES_FLAG_ALL          1.000000\n",
       "HIED_Count5         49.000000\n",
       "HLTH_COUNT1m        23.000000\n",
       "HIED_FLAG            1.000000\n",
       "HLTH_FLAG            1.000000\n",
       "TAZ_ID            2645.000000\n",
       "Tot_Pop           5151.000000\n",
       "TT_Pop          184343.428539\n",
       "Avg                 10.006463\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avgs['HLTH_Walk'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fiscal-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in Avgs.keys():\n",
    "    Avgs[x].to_csv('M:\\LRTP\\LRTP_AvgTT\\Avgs_Walk\\Avg_'+x+'.csv',sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN (works - use for future)\n",
    "\n",
    "##Calculate Averages\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "\n",
    "    #want to end up with a table for each mode for each dest type with these columns: Origin TAZ, Dest TAZ, Time, Tot_Pop\n",
    "    #need to do AM for Healthcare and Essential Services, do MD for HiEd. (three tables per mode)\n",
    "ES_RT = AM_Tables['DAT_RT'].loc[:,ES_list] #restrict columns to just what is an ES destination TAZ\n",
    "ES_RT['Min_Dest_TAZ'] = ES_RT.idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "ES_RT['TravelTime'] = ES_RT.min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "ES_RT = ES_RT.reset_index() #turn index into origin taz field\n",
    "ES_RT = ES_RT.rename(columns = {'index':'origin taz'})\n",
    "\n",
    "ES_RT = ES_RT[['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "#if want to not restrict to just transit (e.g. if O and D are same TAZ)\n",
    "#ES_RT.loc[ES_RT['origin taz'].isin(ES_list), 'Min_Dest_TAZ'] = ES_RT['origin taz'] #if taz is already a dest taz, set D taz to O taz\n",
    "#ES_RT.loc[ES_RT['origin taz'] == ES_RT['Min_Dest_TAZ'], 'TravelTime'] = None #if the taz is a dest taz, set TT to null\n",
    "#note here: so there will never be a transit value if the dest taz is the same as the origin taz\n",
    "#will need to replace with Walk or SOV here - depends on DAT or WAT?\n",
    "ES_RT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base_py_37_omx_geop]",
   "language": "python",
   "name": "conda-env-base_py_37_omx_geop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
