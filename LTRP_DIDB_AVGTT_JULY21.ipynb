{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-liabilities",
   "metadata": {},
   "source": [
    "# Calculating Average Travel Time to Other Destination Categories\n",
    "- Create a feature class for each destination type (healthcare, higher education, essential services) that contains the point locations, types, and capacity data.\n",
    "- For each TAZ, find out how many (and ideally which) destinations of each type are within a buffer of the TAZ centroid.\n",
    "- Flag each TAZ with whether it meets the threshold for the number of destinations within a buffer around the TAZ centroid for the type of destination.\n",
    "- Use model skims for travel times from TAZ centroid to TAZ centroid for all of the following modes: Drive (SOV as proxy), Transit, Rapid Transit, Bus, Walk.\n",
    "- Then pick the minimum time to reach a flagged TAZ and weight by TAZ population and use that for calculation of the average travel time for MPO.\n",
    "- Then flag origin TAZs as whether their minimum distance to a flagged TAZ is within the average threshold for MPO.\n",
    "\n",
    "\n",
    "Environment: base_py_37_omx_geop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import openmatrix as omx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "respiratory-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import all the CSVs that contain skims \n",
    "Walk_skim= omx.open_file('M:/LRTP/LRTP_AvgTT/out/Walk_skim.omx','r')\n",
    "#Import AM\n",
    "DAT_Boat_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_Boat_tr_skim.omx','r')\n",
    "DAT_CommRail_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_CommRail_tr_skim.omx','r')\n",
    "DAT_LocalBus_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_LocalBus_tr_skim.omx','r')\n",
    "DAT_RapidTransit_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/A_DAT_for_RapidTransit_tr_skim2.omx','r')\n",
    "WAT_Transit_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/WAT_for_All_tr_skim.omx','r')\n",
    "SOV_skim_AM = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/SOV_skim.omx','r')\n",
    "\n",
    "#put AM CSVs into Dictionary\n",
    "skims_AM = {'DAT_Boat':DAT_Boat_skim_AM, 'DAT_CR':DAT_CommRail_skim_AM, \n",
    "            'DAT_LB':DAT_LocalBus_skim_AM, 'DAT_RT':DAT_RapidTransit_skim_AM, \n",
    "            'WAT_TR':WAT_Transit_skim_AM, 'SOV':SOV_skim_AM, 'Walk': Walk_skim}\n",
    "\n",
    "#Import MD\n",
    "DAT_Boat_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_Boat_tr_skim.omx','r')\n",
    "DAT_CommRail_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_CommRail_tr_skim.omx','r')\n",
    "DAT_LocalBus_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_LocalBus_tr_skim.omx','r')\n",
    "DAT_RapidTransit_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\A_DAT_for_Rapid_Transit_tr_skim.omx','r')\n",
    "WAT_Transit_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\WAT_for_All_tr_skim.omx','r')\n",
    "SOV_skim_MD = omx.open_file('M:\\LRTP\\LRTP_AvgTT\\out\\MD\\SOV_skim.omx','r')\n",
    "\n",
    "#put MD CSVs into Dictionary\n",
    "skims_MD = {'DAT_Boat':DAT_Boat_skim_MD, 'DAT_CR':DAT_CommRail_skim_MD, \n",
    "            'DAT_LB':DAT_LocalBus_skim_MD, 'DAT_RT':DAT_RapidTransit_skim_MD, \n",
    "            'WAT_TR':WAT_Transit_skim_MD, 'SOV':SOV_skim_MD, 'Walk': Walk_skim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "corresponding-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import TAZ tables for Essential Services, Healthcare, and Higher Ed. \n",
    "dest_TAZs = pd.read_csv(r'M:/LRTP/LRTP_AvgTT/MPO_TAZ_ES_1m2.csv',header=0, sep=',',\n",
    "                        usecols=['taz', 'ES_FLAG_ALL','HIED_Count5', 'HLTH_COUNT1m'])\n",
    "#create table with column for each destination type that flags (0,1) which TAZs pass the destination threshold\n",
    "dest_TAZs['HIED_FLAG']=[1 if x >=1 else 0 for x in dest_TAZs['HIED_Count5']]\n",
    "dest_TAZs['HLTH_FLAG']=[1 if x >=1 else 0 for x in dest_TAZs['HLTH_COUNT1m']]\n",
    "\n",
    "#bring in population data for later\n",
    "tot_pop = pd.read_csv(r'M:/LRTP/LRTP_AvgTT/TAZ_Pop_CTPS.csv', header=0, sep=',', usecols=['TAZ_ID', 'Tot_Pop'])\n",
    "dest_TAZs = dest_TAZs.merge(tot_pop, how='left', left_on='taz', right_on ='TAZ_ID')\n",
    "\n",
    "#dest_TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "amber-mount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1594"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of total TAZs (this is for row and column names for matrices)\n",
    "tazs = dest_TAZs['taz'].tolist()\n",
    "tazs.sort()\n",
    "#make lists of only destination TAZs (this is for averaging)\n",
    "ES_list = dest_TAZs[dest_TAZs['ES_FLAG_ALL']==1]['taz'].tolist()\n",
    "HLTH_list = dest_TAZs[dest_TAZs['HLTH_FLAG']==1]['taz'].tolist()\n",
    "HIED_list = dest_TAZs[dest_TAZs['HIED_FLAG']==1]['taz'].tolist()\n",
    "len(HIED_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "desperate-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trips matrices\n",
    "AM_trips = omx.open_file('M:/LRTP/LRTP_AvgTT/out/AM/AfterSC_Final_AM_Tables.omx','r')\n",
    "MD_trips = omx.open_file('M:/LRTP/LRTP_AvgTT/out/MD/AfterSC_Final_MD_Tables.omx','r')\n",
    "#turn into dataframes\n",
    "AM_trips_DAT = pd.DataFrame((np.array(AM_trips['DAT_Boat'])+np.array(AM_trips['DAT_CR'])+\n",
    "                             np.array(AM_trips['DAT_LB']) +np.array(AM_trips['DAT_RT']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "AM_trips_WAT = pd.DataFrame(np.array(AM_trips['WAT']))\n",
    "                            \n",
    "MD_trips_DAT = pd.DataFrame((np.array(MD_trips['DAT_Boat'])+np.array(MD_trips['DAT_CR'])+\n",
    "                             np.array(MD_trips['DAT_LB']) +np.array(MD_trips['DAT_RT']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "MD_trips_WAT = pd.DataFrame(np.array(MD_trips['WAT']))   \n",
    "\n",
    "#close omx\n",
    "AM_trips.close()\n",
    "MD_trips.close()\n",
    "\n",
    "#make trip total tables for transit so can do weighted average\n",
    "AM_trips_AT = AM_trips_DAT + AM_trips_WAT\n",
    "MD_trips_AT = MD_trips_DAT + MD_trips_WAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "former-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in add\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in add\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: overflow encountered in add\n",
      "C:\\Users\\matkinson\\Anaconda3\\envs\\base_py_37_omx_geop\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: overflow encountered in add\n"
     ]
    }
   ],
   "source": [
    "##Sum the Skims to get Travel Time per Mode by Time of Day (loop through both AM and MD dictionaries)\n",
    "AM_Tables = {}\n",
    "MD_Tables = {}\n",
    "\n",
    "for x in skims_AM.keys():\n",
    "    if x != 'SOV' and x != 'Walk' and x != 'WAT_TR':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['Access Drive Time'])+np.array(skims_AM[x]['Access Walk Time'])\n",
    "                        +np.array(skims_AM[x]['Dwelling Time'])+np.array(skims_AM[x]['Egress Drive Time'])\n",
    "                        +np.array(skims_AM[x]['Egress Walk Time'])+np.array(skims_AM[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_AM[x]['Initial Wait Time'])+np.array(skims_AM[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_AM[x]['Transfer Wait Time'])+np.array(skims_AM[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'WAT_TR':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['Access Walk Time'])\n",
    "                        +np.array(skims_AM[x]['Dwelling Time'])\n",
    "                        +np.array(skims_AM[x]['Egress Walk Time'])+np.array(skims_AM[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_AM[x]['Initial Wait Time'])+np.array(skims_AM[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_AM[x]['Transfer Wait Time'])+np.array(skims_AM[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'SOV':\n",
    "        AM_Tables[x] = pd.DataFrame(np.array(skims_AM[x]['CongTime'])[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'Walk':\n",
    "        AM_Tables[x] = pd.DataFrame((np.array(skims_AM[x]['WalkTime']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        AM_Tables[x][AM_Tables[x] > 60] = None\n",
    "        \n",
    "for x in skims_MD.keys():\n",
    "    if x != 'SOV' and x != 'Walk' and x != 'WAT_TR':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['Access Drive Time'])+np.array(skims_MD[x]['Access Walk Time'])\n",
    "                        +np.array(skims_MD[x]['Dwelling Time'])+np.array(skims_MD[x]['Egress Drive Time'])\n",
    "                        +np.array(skims_MD[x]['Egress Walk Time'])+np.array(skims_MD[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_MD[x]['Initial Wait Time'])+np.array(skims_MD[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_MD[x]['Transfer Wait Time'])+np.array(skims_MD[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'WAT_TR':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['Access Walk Time'])\n",
    "                        +np.array(skims_MD[x]['Dwelling Time'])\n",
    "                        +np.array(skims_MD[x]['Egress Walk Time'])+np.array(skims_MD[x]['In-Vehicle Time'])\n",
    "                        +np.array(skims_MD[x]['Initial Wait Time'])+np.array(skims_MD[x]['Transfer Penalty Time'])\n",
    "                        +np.array(skims_MD[x]['Transfer Wait Time'])+np.array(skims_MD[x]['Transfer Walk Time']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'SOV':\n",
    "        MD_Tables[x] = pd.DataFrame(np.array(skims_MD[x]['CongTime'])[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "    if x == 'Walk':\n",
    "        MD_Tables[x] = pd.DataFrame((np.array(skims_MD[x]['WalkTime']))[1:1902, 1:1902],\n",
    "                                   index=tazs, columns=tazs).replace(-np.inf, np.nan)\n",
    "        MD_Tables[x][MD_Tables[x] > 60] = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "documented-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close everything! \n",
    "Walk_skim.close()\n",
    "\n",
    "DAT_Boat_skim_AM.close()\n",
    "DAT_CommRail_skim_AM.close()\n",
    "DAT_LocalBus_skim_AM.close()\n",
    "DAT_RapidTransit_skim_AM.close()\n",
    "WAT_Transit_skim_AM.close()\n",
    "SOV_skim_AM.close()\n",
    "\n",
    "DAT_Boat_skim_MD.close()\n",
    "DAT_CommRail_skim_MD.close()\n",
    "DAT_LocalBus_skim_MD.close()\n",
    "DAT_RapidTransit_skim_MD.close()\n",
    "WAT_Transit_skim_MD.close()\n",
    "SOV_skim_MD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "concerned-telescope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2636</th>\n",
       "      <th>2637</th>\n",
       "      <th>2638</th>\n",
       "      <th>2639</th>\n",
       "      <th>2640</th>\n",
       "      <th>2641</th>\n",
       "      <th>2642</th>\n",
       "      <th>2643</th>\n",
       "      <th>2644</th>\n",
       "      <th>2645</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.573888</td>\n",
       "      <td>4.297486</td>\n",
       "      <td>7.206461</td>\n",
       "      <td>10.283901</td>\n",
       "      <td>9.656473</td>\n",
       "      <td>15.791207</td>\n",
       "      <td>13.277609</td>\n",
       "      <td>15.498875</td>\n",
       "      <td>14.220582</td>\n",
       "      <td>15.792448</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.668146</td>\n",
       "      <td>2.317301</td>\n",
       "      <td>4.497178</td>\n",
       "      <td>8.701724</td>\n",
       "      <td>5.732557</td>\n",
       "      <td>14.209030</td>\n",
       "      <td>9.353694</td>\n",
       "      <td>11.574959</td>\n",
       "      <td>10.296666</td>\n",
       "      <td>11.614104</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.210739</td>\n",
       "      <td>5.722017</td>\n",
       "      <td>2.446815</td>\n",
       "      <td>5.418783</td>\n",
       "      <td>3.540088</td>\n",
       "      <td>10.926091</td>\n",
       "      <td>7.161224</td>\n",
       "      <td>9.382489</td>\n",
       "      <td>8.104197</td>\n",
       "      <td>10.715492</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.288178</td>\n",
       "      <td>8.799457</td>\n",
       "      <td>5.418783</td>\n",
       "      <td>2.719560</td>\n",
       "      <td>4.257573</td>\n",
       "      <td>9.158111</td>\n",
       "      <td>6.641006</td>\n",
       "      <td>8.862271</td>\n",
       "      <td>7.583979</td>\n",
       "      <td>12.281218</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.898086</td>\n",
       "      <td>7.780061</td>\n",
       "      <td>3.377100</td>\n",
       "      <td>7.299660</td>\n",
       "      <td>2.321564</td>\n",
       "      <td>12.093582</td>\n",
       "      <td>4.804656</td>\n",
       "      <td>7.025921</td>\n",
       "      <td>5.747629</td>\n",
       "      <td>10.396446</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.001623</td>\n",
       "      <td>30.143345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.441559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.143347</td>\n",
       "      <td>14.755394</td>\n",
       "      <td>20.981047</td>\n",
       "      <td>37.407970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.726696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.179579</td>\n",
       "      <td>12.806874</td>\n",
       "      <td>21.934971</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.663385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.451569</td>\n",
       "      <td>26.904104</td>\n",
       "      <td>13.067469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.928933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3          4         5          6     \\\n",
       "1      2.573888  4.297486  7.206461  10.283901  9.656473  15.791207   \n",
       "2      5.668146  2.317301  4.497178   8.701724  5.732557  14.209030   \n",
       "3      7.210739  5.722017  2.446815   5.418783  3.540088  10.926091   \n",
       "4     10.288178  8.799457  5.418783   2.719560  4.257573   9.158111   \n",
       "5      9.898086  7.780061  3.377100   7.299660  2.321564  12.093582   \n",
       "...         ...       ...       ...        ...       ...        ...   \n",
       "2641        NaN       NaN       NaN        NaN       NaN        NaN   \n",
       "2642        NaN       NaN       NaN        NaN       NaN        NaN   \n",
       "2643        NaN       NaN       NaN        NaN       NaN        NaN   \n",
       "2644        NaN       NaN       NaN        NaN       NaN        NaN   \n",
       "2645        NaN       NaN       NaN        NaN       NaN        NaN   \n",
       "\n",
       "           7          8          9          10    ...  2636       2637  \\\n",
       "1     13.277609  15.498875  14.220582  15.792448  ...   NaN        NaN   \n",
       "2      9.353694  11.574959  10.296666  11.614104  ...   NaN        NaN   \n",
       "3      7.161224   9.382489   8.104197  10.715492  ...   NaN        NaN   \n",
       "4      6.641006   8.862271   7.583979  12.281218  ...   NaN        NaN   \n",
       "5      4.804656   7.025921   5.747629  10.396446  ...   NaN        NaN   \n",
       "...         ...        ...        ...        ...  ...   ...        ...   \n",
       "2641        NaN        NaN        NaN        NaN  ...   NaN        NaN   \n",
       "2642        NaN        NaN        NaN        NaN  ...   NaN        NaN   \n",
       "2643        NaN        NaN        NaN        NaN  ...   NaN  33.726696   \n",
       "2644        NaN        NaN        NaN        NaN  ...   NaN  28.663385   \n",
       "2645        NaN        NaN        NaN        NaN  ...   NaN        NaN   \n",
       "\n",
       "           2638  2639  2640       2641       2642       2643       2644  \\\n",
       "1           NaN   NaN   NaN        NaN        NaN        NaN        NaN   \n",
       "2           NaN   NaN   NaN        NaN        NaN        NaN        NaN   \n",
       "3           NaN   NaN   NaN        NaN        NaN        NaN        NaN   \n",
       "4           NaN   NaN   NaN        NaN        NaN        NaN        NaN   \n",
       "5           NaN   NaN   NaN        NaN        NaN        NaN        NaN   \n",
       "...         ...   ...   ...        ...        ...        ...        ...   \n",
       "2641        NaN   NaN   NaN  18.001623  30.143345        NaN        NaN   \n",
       "2642  38.441559   NaN   NaN  30.143347  14.755394  20.981047  37.407970   \n",
       "2643        NaN   NaN   NaN        NaN  21.179579  12.806874  21.934971   \n",
       "2644        NaN   NaN   NaN        NaN  37.451569  26.904104  13.067469   \n",
       "2645        NaN   NaN   NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "           2645  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "...         ...  \n",
       "2641        NaN  \n",
       "2642        NaN  \n",
       "2643        NaN  \n",
       "2644        NaN  \n",
       "2645  12.928933  \n",
       "\n",
       "[1901 rows x 1901 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AM_Tables['Walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "suffering-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make DAT tables (get min for each cell!)\n",
    "AM_Tables['AM_DAT'] = np.fmin(np.fmin(AM_Tables['DAT_Boat'],AM_Tables['DAT_CR']), np.fmin(AM_Tables['DAT_LB'],AM_Tables['DAT_RT']))\n",
    "MD_Tables['MD_DAT'] = np.fmin(np.fmin(MD_Tables['DAT_Boat'],MD_Tables['DAT_CR']), np.fmin(MD_Tables['DAT_LB'],MD_Tables['DAT_RT']))\n",
    "\n",
    "#Create new table in dictionary: All Transit\n",
    "    #take the average - weight it by # of trips for each type of transit\n",
    "#AM_Tables['AM_Transit'] = ((AM_Tables['AM_DAT']*AM_trips_DAT)+(AM_Tables['AM_WAT']*AM_trips_WAT))/(AM_trips_AT)\n",
    "#MD_Tables['MD_Transit'] = ((MD_Tables['MD_DAT']*MD_trips_DAT)+(MD_Tables['MD_WAT']*MD_trips_WAT))/(MD_trips_AT)\n",
    "    #take the lowest\n",
    "#AM_Tables['AM_TR'] = np.fmin(AM_Tables['AM_DAT'], AM_Tables['WAT_TR'])\n",
    "#MD_Tables['MD_TR'] = np.fmin(MD_Tables['MD_DAT'], MD_Tables['WAT_TR'])\n",
    "#use these if no drive access transit\n",
    "AM_Tables['AM_TR'] = AM_Tables['WAT_TR']\n",
    "MD_Tables['MD_TR'] = MD_Tables['WAT_TR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "friendly-lender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin taz</th>\n",
       "      <th>Min_Dest_TAZ</th>\n",
       "      <th>TravelTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>12.735808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>2643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>2644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>2645</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin taz  Min_Dest_TAZ  TravelTime\n",
       "0              1         202.0   12.735808\n",
       "1              2           3.0    3.000000\n",
       "2              3           4.0    4.000000\n",
       "3              4           3.0    3.000000\n",
       "4              5           3.0    3.000000\n",
       "...          ...           ...         ...\n",
       "1896        2641           NaN         NaN\n",
       "1897        2642           NaN         NaN\n",
       "1898        2643           NaN         NaN\n",
       "1899        2644           NaN         NaN\n",
       "1900        2645          15.0   15.000000\n",
       "\n",
       "[1901 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculate Averages\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "\n",
    "    #want to end up with a table for each mode for each dest type with these columns: Origin TAZ, Dest TAZ, Time, Tot_Pop\n",
    "    #need to do AM for Healthcare and Essential Services, do MD for HiEd. (three tables per mode)\n",
    "Avgs = {}\n",
    "#Transit - ES\n",
    "#SOV - ES\n",
    "#Walking - ES\n",
    "for x in ['AM_TR', 'SOV', 'Walk']:\n",
    "    Avgs['ES_'+x] = AM_Tables[x].loc[:,ES_list] #restrict columns to just what is an ES destination TAZ\n",
    "    Avgs['ES_'+x]['Min_Dest_TAZ'] = Avgs['ES_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['ES_'+x]['TravelTime'] = Avgs['ES_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['ES_'+x] = Avgs['ES_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "#Transit - Healthcare\n",
    "#Walking - Healthcare\n",
    "#SOV - Healthcare\n",
    "for x in ['AM_TR', 'SOV', 'Walk']:\n",
    "    Avgs['HLTH_'+x] = AM_Tables[x].loc[:,HLTH_list] #restrict columns to just what is an HLTH destination TAZ\n",
    "    Avgs['HLTH_'+x]['Min_Dest_TAZ'] = Avgs['HLTH_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['HLTH_'+x]['TravelTime'] = Avgs['HLTH_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['HLTH_'+x] = Avgs['HLTH_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "#SOV - HiEd(MD)\n",
    "#Transit - HiEd (MD)\n",
    "#Walking - HiEd\n",
    "for x in ['MD_TR', 'SOV', 'Walk']:\n",
    "    Avgs['HIED_'+x] = MD_Tables[x].loc[:,HIED_list] #restrict columns to just what is an HiED destination TAZ\n",
    "    Avgs['HIED_'+x]['Min_Dest_TAZ'] = Avgs['HIED_'+x].idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "    Avgs['HIED_'+x]['TravelTime'] = Avgs['HIED_'+x].min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x].reset_index() #turn index into origin taz field\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x].rename(columns = {'index':'origin taz'})\n",
    "\n",
    "    Avgs['HIED_'+x] = Avgs['HIED_'+x][['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "\n",
    "#if want to not restrict to just transit (e.g. if O and D are same TAZ)\n",
    "#ES_RT.loc[ES_RT['origin taz'].isin(ES_list), 'Min_Dest_TAZ'] = ES_RT['origin taz'] #if taz is already a dest taz, set D taz to O taz\n",
    "#ES_RT.loc[ES_RT['origin taz'] == ES_RT['Min_Dest_TAZ'], 'TravelTime'] = None #if the taz is a dest taz, set TT to null\n",
    "#note here: so there will never be a transit value if the dest taz is the same as the origin taz\n",
    "#will need to replace with Walk or SOV here - depends on DAT or WAT?\n",
    "Avgs['HIED_MD_TR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "editorial-incidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ES_AM_TR_Avg': 23.055239813307843,\n",
       " 'ES_SOV_Avg': 1.4344942460072214,\n",
       " 'ES_Walk_Avg': 8.66032791433802,\n",
       " 'HLTH_AM_TR_Avg': 26.14402159508965,\n",
       " 'HLTH_SOV_Avg': 2.263966118767715,\n",
       " 'HLTH_Walk_Avg': 10.006462587020875,\n",
       " 'HIED_MD_TR_Avg': 25.4199342019939,\n",
       " 'HIED_SOV_Avg': 2.2477777843488687,\n",
       " 'HIED_Walk_Avg': 7.946976722620972}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Calculate Averages PART 2\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "#actually calculate averages\n",
    "AvgNums = {}\n",
    "for x in Avgs.keys():\n",
    "    Avgs[x] = Avgs[x].merge(dest_TAZs, how = 'left', left_on = 'origin taz', right_on = 'taz') #merge to have all data in one table\n",
    "    Avgs[x]['TT_Pop'] = Avgs[x]['TravelTime']*Avgs[x]['Tot_Pop'] #calculate time * pop (weight)\n",
    "    avg = np.nansum(Avgs[x]['TT_Pop'])/np.nansum(Avgs[x]['Tot_Pop']) #make the actual avg, excluding nan values\n",
    "    AvgNums[x+'_Avg'] = avg #add avg to dictionary with id\n",
    "    Avgs[x]['Avg'] = avg #add a avg field for calc later\n",
    "AvgNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "injured-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make Flag Tables\n",
    "#if the TAZ has access to a destination TAZ within the MPO average for that mode, flag.\n",
    "    #How do I make this into a table?  - maybe copy the TAZ to TAZ table and clear its contents, then just go down the column of all the destination TAZs and query the skim table for that mode and TOD.\n",
    "    #where column name is in list (aka field in the table that flags destination TAZs for each type)\n",
    "for x in Avgs.keys():\n",
    "    Avgs[x]['AvgTT_Flag'] = np.where(Avgs[x]['TravelTime'] <= Avgs[x]['Avg'], 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "editorial-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin taz        2645.000000\n",
       "Min_Dest_TAZ      2642.000000\n",
       "TravelTime          51.282684\n",
       "taz               2645.000000\n",
       "ES_FLAG_ALL          1.000000\n",
       "HIED_Count5         49.000000\n",
       "HLTH_COUNT1m        23.000000\n",
       "HIED_FLAG            1.000000\n",
       "HLTH_FLAG            1.000000\n",
       "TAZ_ID            2645.000000\n",
       "Tot_Pop           5151.000000\n",
       "TT_Pop          184343.428539\n",
       "Avg                 10.006463\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avgs['HLTH_Walk'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fiscal-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in Avgs.keys():\n",
    "    Avgs[x].to_csv('M:\\LRTP\\LRTP_AvgTT\\Avgs_Walk\\Avg_'+x+'.csv',sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN (works - use for future)\n",
    "\n",
    "##Calculate Averages\n",
    "    #weighted average of all the lowest travel times from each TAZ to closest (timewise) destination TAZ \n",
    "        #(ones that pass the destination threshold (flagged)), weighted by population of the origin TAZ.\n",
    "    #do this for all modes and TOD - should end up with a number each for SOV, All Transit, Rapid Transit, Local Bus, Commuter Rail, Boat, and Walking for AM and MD.\n",
    "\n",
    "    #want to end up with a table for each mode for each dest type with these columns: Origin TAZ, Dest TAZ, Time, Tot_Pop\n",
    "    #need to do AM for Healthcare and Essential Services, do MD for HiEd. (three tables per mode)\n",
    "ES_RT = AM_Tables['DAT_RT'].loc[:,ES_list] #restrict columns to just what is an ES destination TAZ\n",
    "ES_RT['Min_Dest_TAZ'] = ES_RT.idxmin(axis=1) #new column with the column name of the smallest time in each row\n",
    "ES_RT['TravelTime'] = ES_RT.min(1) #new column with the min val in each row (corresponds with dest TAZ above)\n",
    "ES_RT = ES_RT.reset_index() #turn index into origin taz field\n",
    "ES_RT = ES_RT.rename(columns = {'index':'origin taz'})\n",
    "\n",
    "ES_RT = ES_RT[['origin taz', 'Min_Dest_TAZ', 'TravelTime']] #restrict to a manageable table\n",
    "\n",
    "#if want to not restrict to just transit (e.g. if O and D are same TAZ)\n",
    "#ES_RT.loc[ES_RT['origin taz'].isin(ES_list), 'Min_Dest_TAZ'] = ES_RT['origin taz'] #if taz is already a dest taz, set D taz to O taz\n",
    "#ES_RT.loc[ES_RT['origin taz'] == ES_RT['Min_Dest_TAZ'], 'TravelTime'] = None #if the taz is a dest taz, set TT to null\n",
    "#note here: so there will never be a transit value if the dest taz is the same as the origin taz\n",
    "#will need to replace with Walk or SOV here - depends on DAT or WAT?\n",
    "ES_RT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base_py_37_omx_geop]",
   "language": "python",
   "name": "conda-env-base_py_37_omx_geop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
